<div align="center">

# MWDLP <!-- omit in toc -->
<!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook] -->
[![Paper](http://img.shields.io/badge/paper-arxiv.2105.09856-B31B1B.svg)][paper]  

</div>

Clone of official implmentation of neural vocoder "MWDLP".

<!-- generated by [Markdown All in One](https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one) -->
- [Demo](#demo)
- [How to Use](#how-to-use)
- [Original paper](#original-paper)
- [Difference from original research](#difference-from-original-research)
- [Contact](#contact)

Real-time implementation is based on [LPCNet](https://github.com/mozilla/LPCNet/).

## Demo
[samples](https://demo-mwdlp-interspeech2021.audioeval.net/)

## How to Use
<!-- ### Quick training <!- omit in toc ->
Jump to **[Notebook in Google Colaboratory][notebook]**, then Run. that's all!!  
 -->
### Install <!-- omit in toc -->
maybe (not yet checked by myself)  

#### Requirements:
- UNIX
- 3.6 <= python <= 3.9
- CUDA 11.1
- jq
- make
- gcc

#### install
```bash
$ cd ../../tools
$ make
$ cd ..
```



### Training <!-- omit in toc -->
Preprocessing -> 4-step Training -> Clang model compiling -> 2 Demo  

Three core scripts: `download_vcc20.sh`, `run.sh` and `run_realtime.sh`  
Manually update variables in the script, then run it.  

| Purpose                          |       Script        |     Variables              | Notes           |
| -------------------------------- | ------------------- | -------------------------- |---------------- |
| Data download                    | `download_vcc20.sh` |    -                       |                 |
| Preprocessing                    | `run.sh`            | `stage=0init123` & `n_jobs=` | thread number |
| Vocoder training                 | `run.sh`            | `stage=4` & `GPU_device=X` | take ~ 4   days |
| Compile CPU real-time program    | `run_realtime.sh`   | `stage=0`                  |                 |
| Analysis-synthesis               | `run_realtime.sh`   | `stage=1` & `spks_dec=`    | speaker ID      |
| Decode w/ mel-spec output/input  | `run_realtime.sh`   | `stage=2` & `spks_dec=`    |                 |

<!-- ### Training Speed <!- omit in toc ->
3.37 [iter/sec] @ NVIDIA T4 Google Colaboratory (AMP+)
 -->
 
## Original paper
[![Paper](http://img.shields.io/badge/paper-arxiv.2105.09856-B31B1B.svg)][paper]  
<!-- https://arxiv2bibtex.org/?q=2105.09856&format=bibtex -->
```
@misc{2105.09856,
Author = {Patrick Lumban Tobing and Tomoki Toda},
Title = {High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling},
Year = {2021},
Eprint = {arXiv:2105.09856},
}
```

[paper]:https://arxiv.org/abs/2105.09856

## Difference from original research
- Dataset
  - Paper: Mixed 300 speakers (estimated 25 hours)
  - This impl.: [Voice Conversion Challenge 2020 dataset / VCC20](http://vc-challenge.org/)

## Contact
Please check original repository.
